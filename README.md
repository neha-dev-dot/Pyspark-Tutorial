# ğŸ”¥ PySpark Essentials

This project is a hands-on collection of notebooks, code snippets, and exercises focused on learning **Apache Spark with Python (PySpark)**. It includes my notes and experiments while exploring **core Spark concepts, transformations, actions, DataFrame API, and more**.

---

## ğŸš€ What is PySpark?

**PySpark** is the Python API for **Apache Spark**, a powerful open-source distributed computing engine used for large-scale data processing and analytics. PySpark allows you to leverage the power of distributed computing using Python.

---

## ğŸ“˜ Topics Covered

- âœ… Introduction to Spark & PySpark  
- âœ… SparkContext & SparkSession  
- âœ… RDDs (Resilient Distributed Datasets)  
- âœ… DataFrames & Datasets  
- âœ… Transformations vs Actions  
- âœ… Reading/Writing: JSON, CSV, Parquet  
- âœ… PySpark SQL & Queries  
- âœ… GroupBy, Aggregations, Joins  
- âœ… Handling Nulls & Missing Data  
- âœ… User-Defined Functions (UDFs)  
- âœ… Window Functions  
- âœ… Data Partitioning & Performance Optimization  
- âœ… Intro to MLlib (Optional)

---

## âœï¸ How I Learn
I follow a "Learn by Doing" approach.
Each notebook contains:

âœ… Detailed explanations

ğŸ§ª Hands-on code examples

ğŸ“Œ Real-world case studies

âœ… Practice tasks




